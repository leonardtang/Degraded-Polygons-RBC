{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonardtang/NAP/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faaTqQKHtiQq"
      },
      "outputs": [],
      "source": [
        "# Create shapes dataset\n",
        "# Remove corners from each shape and save to new folder\n",
        "# Remove edges from each shape and save to new folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eErpnppqtiQs"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "import argparse\n",
        "from torchvision import datasets, models, transforms\n",
        "import pandas as pd\n",
        "# from meter_utils import AverageMeter, ProgressMeter\n",
        "import time\n",
        "\n",
        "classes = [3, 4, 5, 6, 7, 8]\n",
        "num_per_class = 1000\n",
        "imgsize = 200\n",
        "min_radius = 20\n",
        "thickness = 2\n",
        "bg_color = (255, 255, 255)\n",
        "fg_color = (0, 0, 0)\n",
        "saveto = \"./images/shapes/\"\n",
        "corner_hide = 0.3 # Fraction of shape radius, such that a circle of bg_color will be drawn around each corner with this radius to hide the corner\n",
        "edge_hide = 0.3 # Fraction of shape radius, such that a circle of bg_color will be drawn around center of each edge with this radius to hide the edge\n",
        "\n",
        "if not os.path.exists(saveto):\n",
        "    os.makedirs(saveto)\n",
        "\n",
        "for side in classes:\n",
        "    for k in range(num_per_class):\n",
        "        suffix = 'whole' # Save image with suffix to indicate corner_hide, edge_hide, or whole\n",
        "        # Create a blank image\n",
        "        img = np.zeros((imgsize, imgsize, 3), np.uint8)\n",
        "        img[:] = bg_color\n",
        "        # Randomly select a point on the image\n",
        "        x = np.random.randint(min_radius + math.ceil(thickness/2) + 1, imgsize-min_radius - math.ceil(thickness/2))\n",
        "        y = np.random.randint(min_radius + math.ceil(thickness/2) + 1, imgsize-min_radius - math.ceil(thickness/2))\n",
        "        # Get max radius of polygon\n",
        "        max_radius = min(x, y, imgsize - x, imgsize - y)\n",
        "        # Randomly select a radius\n",
        "        radius = np.random.randint(min_radius, max_radius)\n",
        "        # Randomly choose a starting angle\n",
        "        angle = np.random.randint(0, 360)\n",
        "        angle = angle * np.pi / 180 # Convert to radians\n",
        "        # Get list of points in polar coordinates\n",
        "        if side > 2:\n",
        "            angles = [angle + 2 * np.pi * i / side for i in range(side)]\n",
        "            points = np.array([(x + radius * np.cos(angle), y + radius * np.sin(angle)) for angle in angles], np.int32)\n",
        "            # Draw polygon\n",
        "            img = cv2.polylines(img, [points], True, fg_color, thickness)\n",
        "            # Save image\n",
        "            cv2.imwrite(f'{saveto}{side}_{k}_whole.png', img)\n",
        "            # Make copy of image with corners hidden\n",
        "            img_nocorners = img.copy()\n",
        "            for i in range(side):\n",
        "                cv2.circle(img_nocorners, (points[i][0], points[i][1]), math.ceil(corner_hide * radius), bg_color, -1)\n",
        "            # Save image\n",
        "            cv2.imwrite(f'{saveto}{side}_{k}_nocorners.png', img_nocorners)\n",
        "            # Make copy of image with edges hidden\n",
        "            img_noedges = img.copy()\n",
        "            for i in range(side):\n",
        "                cv2.circle(img_noedges, (int((points[i][0] + points[(i + 1) % side][0]) / 2), int((points[i][1] + points[(i + 1) % side][1]) / 2)), math.ceil(edge_hide * radius), bg_color, -1)\n",
        "            # Save image\n",
        "            cv2.imwrite(f'{saveto}{side}_{k}_noedges.png', img_noedges)\n",
        "        elif side == 1:\n",
        "            # Draw circle\n",
        "            img = cv2.circle(img, (x, y), radius, fg_color, thickness)\n",
        "            # Save image\n",
        "            cv2.imwrite(f'{saveto}{side}_{k}_whole.png', img)\n",
        "        else:\n",
        "            print(\"Invalid side number\")\n",
        "\n",
        "# Generate metadata df for whole shapes dataset\n",
        "for type in ['whole', 'nocorners', 'noedges']:\n",
        "    df = pd.DataFrame(columns=['filename', 'label'])\n",
        "    for path in os.listdir(saveto):\n",
        "        if path.endswith(f'_{type}.png'):\n",
        "            df = pd.concat([df, pd.DataFrame([[path, int(path.split('_')[0])]], columns=['filename', 'label'])])\n",
        "    df.to_csv(f'{saveto}metadata_{type}.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44fW5L5cwuwB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gE5Fc-v5RweT"
      },
      "outputs": [],
      "source": [
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-Y6AI2tNtiQv",
        "outputId": "1c52f12f-f807-4737-c7bf-7a671e7b0d67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Dropout(p=0.5, inplace=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): Dropout(p=0.5, inplace=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): Dropout(p=0.5, inplace=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): Dropout(p=0.5, inplace=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): Dropout(p=0.5, inplace=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): Dropout(p=0.5, inplace=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): Dropout(p=0.5, inplace=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): Dropout(p=0.5, inplace=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): Dropout(p=0.5, inplace=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): Dropout(p=0.5, inplace=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): Dropout(p=0.5, inplace=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): Dropout(p=0.5, inplace=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): Dropout(p=0.5, inplace=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "Epoch: [0][ 0/37]\tTime  0.942 ( 0.942)\tData  0.800 ( 0.800)\tLoss 2.3819e+02 (2.3819e+02)\tAcc@1   0.00 (  0.00)\tAcc@5   0.78 (  0.78)\n",
            "Train * Acc@1 0.000 Acc@5 0.781\n",
            "Train * Acc@1 6.641 Acc@5 41.016\n",
            "Train * Acc@1 9.635 Acc@5 56.250\n",
            "Train * Acc@1 12.500 Acc@5 63.867\n",
            "Train * Acc@1 13.594 Acc@5 68.125\n",
            "Train * Acc@1 14.323 Acc@5 71.094\n",
            "Train * Acc@1 15.290 Acc@5 73.438\n",
            "Train * Acc@1 15.332 Acc@5 75.293\n",
            "Train * Acc@1 15.365 Acc@5 75.868\n",
            "Train * Acc@1 15.000 Acc@5 76.641\n",
            "Epoch: [0][10/37]\tTime  4.147 ( 2.532)\tData  4.018 ( 2.402)\tLoss 5.3965e+00 (5.3320e+01)\tAcc@1  17.19 ( 15.20)\tAcc@5  78.12 ( 76.78)\n",
            "Train * Acc@1 15.199 Acc@5 76.776\n",
            "Train * Acc@1 15.299 Acc@5 76.953\n",
            "Train * Acc@1 15.385 Acc@5 77.644\n",
            "Train * Acc@1 15.848 Acc@5 77.511\n",
            "Train * Acc@1 15.677 Acc@5 78.073\n",
            "Train * Acc@1 15.723 Acc@5 78.418\n",
            "Train * Acc@1 15.947 Acc@5 78.814\n",
            "Train * Acc@1 15.972 Acc@5 79.210\n",
            "Train * Acc@1 15.995 Acc@5 79.482\n",
            "Train * Acc@1 16.016 Acc@5 79.766\n",
            "Epoch: [0][20/37]\tTime  7.335 ( 4.131)\tData  7.207 ( 4.002)\tLoss 4.0744e+00 (3.0004e+01)\tAcc@1  15.62 ( 16.00)\tAcc@5  85.16 ( 80.02)\n",
            "Train * Acc@1 15.997 Acc@5 80.022\n",
            "Train * Acc@1 15.803 Acc@5 80.114\n",
            "Train * Acc@1 15.557 Acc@5 80.231\n",
            "Train * Acc@1 15.658 Acc@5 80.339\n",
            "Train * Acc@1 15.594 Acc@5 80.469\n",
            "Train * Acc@1 15.715 Acc@5 80.709\n",
            "Train * Acc@1 15.770 Acc@5 80.729\n",
            "Train * Acc@1 15.792 Acc@5 80.831\n",
            "Train * Acc@1 15.787 Acc@5 80.900\n",
            "Train * Acc@1 15.755 Acc@5 80.885\n",
            "Epoch: [0][30/37]\tTime 10.541 ( 5.731)\tData 10.412 ( 5.602)\tLoss 3.7107e+00 (2.1697e+01)\tAcc@1  20.31 ( 15.90)\tAcc@5  87.50 ( 81.10)\n",
            "Train * Acc@1 15.902 Acc@5 81.099\n",
            "Train * Acc@1 15.723 Acc@5 81.030\n",
            "Train * Acc@1 15.838 Acc@5 81.203\n",
            "Train * Acc@1 15.855 Acc@5 81.135\n",
            "Train * Acc@1 15.759 Acc@5 81.004\n",
            "Train * Acc@1 15.929 Acc@5 81.207\n",
            "Train * Acc@1 16.132 Acc@5 81.271\n",
            "Test: [0/4]\tTime  0.854 ( 0.854)\tLoss 5.1515e+00 (5.1515e+00)\tAcc@1  13.28 ( 13.28)\tAcc@5  80.47 ( 80.47)\n",
            "Val * Acc@1 14.453 Acc@5 81.836\n",
            "Epoch: [1][ 0/37]\tTime  0.951 ( 0.951)\tData  0.811 ( 0.811)\tLoss 5.0533e+00 (5.0533e+00)\tAcc@1  20.31 ( 20.31)\tAcc@5  75.78 ( 75.78)\n",
            "Train * Acc@1 20.312 Acc@5 75.781\n",
            "Train * Acc@1 19.141 Acc@5 81.641\n",
            "Train * Acc@1 16.927 Acc@5 82.552\n",
            "Train * Acc@1 16.602 Acc@5 82.031\n",
            "Train * Acc@1 17.188 Acc@5 83.281\n",
            "Train * Acc@1 16.927 Acc@5 83.333\n",
            "Train * Acc@1 17.299 Acc@5 83.371\n",
            "Train * Acc@1 16.602 Acc@5 83.496\n",
            "Train * Acc@1 16.840 Acc@5 83.941\n",
            "Train * Acc@1 16.953 Acc@5 83.438\n",
            "Epoch: [1][10/37]\tTime  4.217 ( 2.568)\tData  4.087 ( 2.438)\tLoss 3.8779e+00 (4.0378e+00)\tAcc@1  18.75 ( 17.12)\tAcc@5  83.59 ( 83.45)\n",
            "Train * Acc@1 17.116 Acc@5 83.452\n",
            "Train * Acc@1 16.927 Acc@5 83.594\n",
            "Train * Acc@1 16.947 Acc@5 83.594\n",
            "Train * Acc@1 16.685 Acc@5 83.873\n",
            "Train * Acc@1 16.719 Acc@5 83.958\n",
            "Train * Acc@1 16.650 Acc@5 84.033\n",
            "Train * Acc@1 16.452 Acc@5 84.375\n",
            "Train * Acc@1 16.493 Acc@5 84.115\n",
            "Train * Acc@1 16.694 Acc@5 84.211\n",
            "Train * Acc@1 16.719 Acc@5 84.062\n",
            "Epoch: [1][20/37]\tTime  7.463 ( 4.199)\tData  7.335 ( 4.070)\tLoss 4.2120e+00 (3.8968e+00)\tAcc@1  14.84 ( 16.63)\tAcc@5  78.12 ( 83.78)\n",
            "Train * Acc@1 16.629 Acc@5 83.780\n",
            "Train * Acc@1 16.797 Acc@5 83.842\n",
            "Train * Acc@1 16.780 Acc@5 83.764\n",
            "Train * Acc@1 16.862 Acc@5 83.919\n",
            "Train * Acc@1 16.875 Acc@5 83.562\n",
            "Train * Acc@1 16.827 Acc@5 83.684\n",
            "Train * Acc@1 16.580 Acc@5 83.565\n",
            "Train * Acc@1 16.574 Acc@5 83.705\n",
            "Train * Acc@1 16.756 Acc@5 83.809\n",
            "Train * Acc@1 16.927 Acc@5 83.854\n",
            "Epoch: [1][30/37]\tTime 10.691 ( 5.820)\tData 10.562 ( 5.691)\tLoss 3.5205e+00 (3.8040e+00)\tAcc@1  17.97 ( 16.96)\tAcc@5  84.38 ( 83.87)\n",
            "Train * Acc@1 16.961 Acc@5 83.871\n",
            "Train * Acc@1 16.846 Acc@5 83.716\n",
            "Train * Acc@1 17.093 Acc@5 83.665\n",
            "Train * Acc@1 16.981 Acc@5 83.778\n",
            "Train * Acc@1 17.031 Acc@5 83.594\n",
            "Train * Acc@1 16.970 Acc@5 83.594\n",
            "Train * Acc@1 16.892 Acc@5 83.573\n",
            "Test: [0/4]\tTime  0.858 ( 0.858)\tLoss 4.2700e+00 (4.2700e+00)\tAcc@1  17.97 ( 17.97)\tAcc@5  81.25 ( 81.25)\n",
            "Val * Acc@1 21.289 Acc@5 81.641\n",
            "Epoch: [2][ 0/37]\tTime  0.959 ( 0.959)\tData  0.814 ( 0.814)\tLoss 3.2851e+00 (3.2851e+00)\tAcc@1  14.84 ( 14.84)\tAcc@5  84.38 ( 84.38)\n",
            "Train * Acc@1 14.844 Acc@5 84.375\n",
            "Train * Acc@1 14.062 Acc@5 85.156\n",
            "Train * Acc@1 12.760 Acc@5 84.896\n",
            "Train * Acc@1 13.086 Acc@5 84.961\n",
            "Train * Acc@1 13.750 Acc@5 84.844\n",
            "Train * Acc@1 14.062 Acc@5 85.156\n",
            "Train * Acc@1 14.509 Acc@5 84.263\n",
            "Train * Acc@1 14.941 Acc@5 84.277\n",
            "Train * Acc@1 15.278 Acc@5 84.375\n",
            "Train * Acc@1 15.234 Acc@5 84.297\n",
            "Epoch: [2][10/37]\tTime  4.241 ( 2.594)\tData  4.112 ( 2.463)\tLoss 3.1457e+00 (3.1887e+00)\tAcc@1  21.88 ( 15.84)\tAcc@5  82.81 ( 84.16)\n",
            "Train * Acc@1 15.838 Acc@5 84.162\n",
            "Train * Acc@1 16.081 Acc@5 84.310\n",
            "Train * Acc@1 16.106 Acc@5 84.315\n",
            "Train * Acc@1 16.016 Acc@5 84.319\n",
            "Train * Acc@1 16.302 Acc@5 84.323\n",
            "Train * Acc@1 16.650 Acc@5 84.424\n",
            "Train * Acc@1 16.636 Acc@5 84.237\n",
            "Train * Acc@1 16.493 Acc@5 83.941\n",
            "Train * Acc@1 16.571 Acc@5 83.676\n",
            "Train * Acc@1 16.367 Acc@5 83.438\n",
            "Epoch: [2][20/37]\tTime  7.491 ( 4.220)\tData  7.361 ( 4.089)\tLoss 2.7062e+00 (3.0989e+00)\tAcc@1  15.62 ( 16.33)\tAcc@5  87.50 ( 83.63)\n",
            "Train * Acc@1 16.332 Acc@5 83.631\n",
            "Train * Acc@1 16.335 Acc@5 83.487\n",
            "Train * Acc@1 16.338 Acc@5 83.356\n",
            "Train * Acc@1 16.341 Acc@5 83.301\n",
            "Train * Acc@1 16.406 Acc@5 83.469\n",
            "Train * Acc@1 16.196 Acc@5 83.383\n",
            "Train * Acc@1 16.377 Acc@5 83.478\n",
            "Train * Acc@1 16.378 Acc@5 83.510\n",
            "Train * Acc@1 16.460 Acc@5 83.567\n",
            "Train * Acc@1 16.432 Acc@5 83.464\n",
            "Epoch: [2][30/37]\tTime 10.740 ( 5.848)\tData 10.612 ( 5.718)\tLoss 2.6019e+00 (3.0017e+00)\tAcc@1  21.88 ( 16.61)\tAcc@5  85.16 ( 83.52)\n",
            "Train * Acc@1 16.608 Acc@5 83.518\n",
            "Train * Acc@1 16.699 Acc@5 83.569\n",
            "Train * Acc@1 16.667 Acc@5 83.523\n",
            "Train * Acc@1 16.659 Acc@5 83.433\n",
            "Train * Acc@1 16.540 Acc@5 83.527\n",
            "Train * Acc@1 16.732 Acc@5 83.529\n",
            "Train * Acc@1 16.596 Acc@5 83.594\n",
            "Test: [0/4]\tTime  0.857 ( 0.857)\tLoss 3.3325e+00 (3.3325e+00)\tAcc@1  15.62 ( 15.62)\tAcc@5  78.12 ( 78.12)\n",
            "Val * Acc@1 19.922 Acc@5 82.031\n",
            "Epoch: [3][ 0/37]\tTime  0.960 ( 0.960)\tData  0.820 ( 0.820)\tLoss 2.7298e+00 (2.7298e+00)\tAcc@1  20.31 ( 20.31)\tAcc@5  77.34 ( 77.34)\n",
            "Train * Acc@1 20.312 Acc@5 77.344\n",
            "Train * Acc@1 17.578 Acc@5 83.594\n",
            "Train * Acc@1 18.490 Acc@5 83.594\n",
            "Train * Acc@1 16.602 Acc@5 82.422\n",
            "Train * Acc@1 15.781 Acc@5 82.812\n",
            "Train * Acc@1 16.797 Acc@5 83.724\n",
            "Train * Acc@1 15.513 Acc@5 83.147\n",
            "Train * Acc@1 16.211 Acc@5 82.910\n",
            "Train * Acc@1 15.451 Acc@5 83.073\n",
            "Train * Acc@1 15.391 Acc@5 83.125\n",
            "Epoch: [3][10/37]\tTime  4.261 ( 2.599)\tData  4.130 ( 2.469)\tLoss 2.4815e+00 (2.5092e+00)\tAcc@1  14.06 ( 15.27)\tAcc@5  81.25 ( 82.95)\n",
            "Train * Acc@1 15.270 Acc@5 82.955\n",
            "Train * Acc@1 15.039 Acc@5 82.747\n",
            "Train * Acc@1 15.084 Acc@5 82.572\n",
            "Train * Acc@1 14.955 Acc@5 82.310\n",
            "Train * Acc@1 15.573 Acc@5 82.240\n",
            "Train * Acc@1 15.430 Acc@5 82.227\n",
            "Train * Acc@1 15.257 Acc@5 82.537\n",
            "Train * Acc@1 15.234 Acc@5 82.769\n",
            "Train * Acc@1 15.543 Acc@5 82.936\n",
            "Train * Acc@1 15.625 Acc@5 82.773\n",
            "Epoch: [3][20/37]\tTime  7.456 ( 4.222)\tData  7.328 ( 4.093)\tLoss 2.1401e+00 (2.4132e+00)\tAcc@1  11.72 ( 15.44)\tAcc@5  90.62 ( 83.15)\n",
            "Train * Acc@1 15.439 Acc@5 83.147\n",
            "Train * Acc@1 15.625 Acc@5 83.381\n",
            "Train * Acc@1 15.625 Acc@5 83.254\n",
            "Train * Acc@1 15.820 Acc@5 83.171\n",
            "Train * Acc@1 16.094 Acc@5 83.219\n",
            "Train * Acc@1 16.046 Acc@5 83.233\n",
            "Train * Acc@1 16.175 Acc@5 83.275\n",
            "Train * Acc@1 16.099 Acc@5 83.315\n",
            "Train * Acc@1 16.218 Acc@5 83.594\n",
            "Train * Acc@1 16.250 Acc@5 83.672\n",
            "Epoch: [3][30/37]\tTime 10.670 ( 5.833)\tData 10.541 ( 5.704)\tLoss 2.2235e+00 (2.3338e+00)\tAcc@1  13.28 ( 16.15)\tAcc@5  77.34 ( 83.47)\n",
            "Train * Acc@1 16.154 Acc@5 83.468\n",
            "Train * Acc@1 16.113 Acc@5 83.398\n",
            "Train * Acc@1 16.170 Acc@5 83.594\n",
            "Train * Acc@1 16.131 Acc@5 83.709\n",
            "Train * Acc@1 15.938 Acc@5 83.683\n",
            "Train * Acc@1 16.102 Acc@5 83.854\n",
            "Train * Acc@1 16.026 Acc@5 83.784\n",
            "Test: [0/4]\tTime  0.860 ( 0.860)\tLoss 2.6867e+00 (2.6867e+00)\tAcc@1  22.66 ( 22.66)\tAcc@5  86.72 ( 86.72)\n",
            "Val * Acc@1 19.336 Acc@5 83.398\n",
            "Epoch: [4][ 0/37]\tTime  0.974 ( 0.974)\tData  0.831 ( 0.831)\tLoss 2.0752e+00 (2.0752e+00)\tAcc@1  19.53 ( 19.53)\tAcc@5  80.47 ( 80.47)\n",
            "Train * Acc@1 19.531 Acc@5 80.469\n",
            "Train * Acc@1 19.922 Acc@5 81.641\n",
            "Train * Acc@1 17.969 Acc@5 82.031\n",
            "Train * Acc@1 17.383 Acc@5 82.812\n",
            "Train * Acc@1 17.812 Acc@5 82.344\n",
            "Train * Acc@1 18.099 Acc@5 82.682\n",
            "Train * Acc@1 17.969 Acc@5 82.924\n",
            "Train * Acc@1 17.383 Acc@5 83.008\n",
            "Train * Acc@1 17.101 Acc@5 83.420\n",
            "Train * Acc@1 17.500 Acc@5 83.359\n",
            "Epoch: [4][10/37]\tTime  4.247 ( 2.603)\tData  4.117 ( 2.471)\tLoss 2.0504e+00 (2.0266e+00)\tAcc@1  12.50 ( 17.05)\tAcc@5  83.59 ( 83.38)\n",
            "Train * Acc@1 17.045 Acc@5 83.381\n",
            "Train * Acc@1 16.862 Acc@5 83.203\n",
            "Train * Acc@1 17.067 Acc@5 83.413\n",
            "Train * Acc@1 16.964 Acc@5 83.482\n",
            "Train * Acc@1 16.875 Acc@5 83.490\n",
            "Train * Acc@1 16.797 Acc@5 83.447\n",
            "Train * Acc@1 16.406 Acc@5 83.456\n",
            "Train * Acc@1 16.363 Acc@5 83.420\n",
            "Train * Acc@1 16.694 Acc@5 83.635\n",
            "Train * Acc@1 16.680 Acc@5 83.516\n",
            "Epoch: [4][20/37]\tTime  7.483 ( 4.227)\tData  7.354 ( 4.096)\tLoss 1.9044e+00 (1.9933e+00)\tAcc@1  16.41 ( 16.67)\tAcc@5  86.72 ( 83.67)\n",
            "Train * Acc@1 16.667 Acc@5 83.668\n",
            "Train * Acc@1 16.690 Acc@5 83.700\n",
            "Train * Acc@1 16.542 Acc@5 83.798\n",
            "Train * Acc@1 16.602 Acc@5 83.757\n",
            "Train * Acc@1 16.469 Acc@5 83.750\n",
            "Train * Acc@1 16.647 Acc@5 83.804\n",
            "Train * Acc@1 16.638 Acc@5 83.912\n",
            "Train * Acc@1 16.602 Acc@5 83.845\n",
            "Train * Acc@1 16.595 Acc@5 83.648\n",
            "Train * Acc@1 16.536 Acc@5 83.750\n",
            "Epoch: [4][30/37]\tTime 10.710 ( 5.843)\tData 10.581 ( 5.713)\tLoss 1.9156e+00 (1.9707e+00)\tAcc@1  14.06 ( 16.46)\tAcc@5  85.94 ( 83.82)\n",
            "Train * Acc@1 16.457 Acc@5 83.821\n",
            "Train * Acc@1 16.455 Acc@5 83.838\n",
            "Train * Acc@1 16.383 Acc@5 83.736\n",
            "Train * Acc@1 16.452 Acc@5 83.617\n",
            "Train * Acc@1 16.295 Acc@5 83.571\n",
            "Train * Acc@1 16.385 Acc@5 83.594\n",
            "Train * Acc@1 16.343 Acc@5 83.742\n",
            "Test: [0/4]\tTime  0.861 ( 0.861)\tLoss 2.4386e+00 (2.4386e+00)\tAcc@1  17.19 ( 17.19)\tAcc@5  82.03 ( 82.03)\n",
            "Val * Acc@1 17.773 Acc@5 84.961\n",
            "Epoch: [5][ 0/37]\tTime  0.959 ( 0.959)\tData  0.816 ( 0.816)\tLoss 1.8670e+00 (1.8670e+00)\tAcc@1  16.41 ( 16.41)\tAcc@5  85.16 ( 85.16)\n",
            "Train * Acc@1 16.406 Acc@5 85.156\n",
            "Train * Acc@1 16.797 Acc@5 83.203\n",
            "Train * Acc@1 16.146 Acc@5 82.812\n",
            "Train * Acc@1 16.992 Acc@5 82.812\n",
            "Train * Acc@1 16.875 Acc@5 83.750\n",
            "Train * Acc@1 15.885 Acc@5 83.073\n",
            "Train * Acc@1 15.179 Acc@5 82.924\n",
            "Train * Acc@1 15.234 Acc@5 82.617\n",
            "Train * Acc@1 15.365 Acc@5 82.465\n",
            "Train * Acc@1 14.766 Acc@5 82.422\n",
            "Epoch: [5][10/37]\tTime  4.274 ( 2.617)\tData  4.145 ( 2.487)\tLoss 1.8600e+00 (1.8937e+00)\tAcc@1  20.31 ( 15.27)\tAcc@5  85.16 ( 82.67)\n",
            "Train * Acc@1 15.270 Acc@5 82.670\n",
            "Train * Acc@1 15.625 Acc@5 82.878\n",
            "Train * Acc@1 16.226 Acc@5 82.752\n",
            "Train * Acc@1 16.518 Acc@5 82.757\n",
            "Train * Acc@1 16.667 Acc@5 82.917\n",
            "Train * Acc@1 16.797 Acc@5 82.959\n",
            "Train * Acc@1 16.820 Acc@5 82.950\n",
            "Train * Acc@1 16.580 Acc@5 83.160\n",
            "Train * Acc@1 16.571 Acc@5 82.977\n",
            "Train * Acc@1 16.719 Acc@5 83.086\n",
            "Epoch: [5][20/37]\tTime  7.566 ( 4.260)\tData  7.437 ( 4.130)\tLoss 1.8774e+00 (1.8817e+00)\tAcc@1  21.88 ( 16.96)\tAcc@5  79.69 ( 82.92)\n",
            "Train * Acc@1 16.964 Acc@5 82.924\n",
            "Train * Acc@1 16.655 Acc@5 83.061\n",
            "Train * Acc@1 16.780 Acc@5 83.084\n",
            "Train * Acc@1 16.992 Acc@5 83.138\n",
            "Train * Acc@1 16.906 Acc@5 83.375\n",
            "Train * Acc@1 16.917 Acc@5 83.323\n",
            "Train * Acc@1 17.043 Acc@5 83.247\n",
            "Train * Acc@1 16.964 Acc@5 83.119\n",
            "Train * Acc@1 16.945 Acc@5 83.190\n",
            "Train * Acc@1 16.927 Acc@5 83.177\n",
            "Epoch: [5][30/37]\tTime 10.823 ( 5.902)\tData 10.694 ( 5.772)\tLoss 1.8835e+00 (1.8776e+00)\tAcc@1  19.53 ( 17.01)\tAcc@5  79.69 ( 83.06)\n",
            "Train * Acc@1 17.011 Acc@5 83.065\n",
            "Train * Acc@1 17.041 Acc@5 83.276\n",
            "Train * Acc@1 17.140 Acc@5 83.357\n",
            "Train * Acc@1 17.050 Acc@5 83.341\n",
            "Train * Acc@1 17.031 Acc@5 83.326\n",
            "Train * Acc@1 17.014 Acc@5 83.442\n",
            "Train * Acc@1 16.955 Acc@5 83.383\n",
            "Test: [0/4]\tTime  0.870 ( 0.870)\tLoss 2.3330e+00 (2.3330e+00)\tAcc@1  14.06 ( 14.06)\tAcc@5  86.72 ( 86.72)\n",
            "Val * Acc@1 18.555 Acc@5 83.398\n",
            "Epoch: [6][ 0/37]\tTime  0.972 ( 0.972)\tData  0.833 ( 0.833)\tLoss 1.8498e+00 (1.8498e+00)\tAcc@1  15.62 ( 15.62)\tAcc@5  85.94 ( 85.94)\n",
            "Train * Acc@1 15.625 Acc@5 85.938\n",
            "Train * Acc@1 18.359 Acc@5 86.328\n",
            "Train * Acc@1 18.229 Acc@5 85.938\n",
            "Train * Acc@1 18.555 Acc@5 86.133\n",
            "Train * Acc@1 18.438 Acc@5 86.250\n",
            "Train * Acc@1 18.099 Acc@5 86.979\n",
            "Train * Acc@1 17.969 Acc@5 87.054\n",
            "Train * Acc@1 17.578 Acc@5 86.816\n",
            "Train * Acc@1 17.448 Acc@5 86.545\n",
            "Train * Acc@1 17.656 Acc@5 86.328\n",
            "Epoch: [6][10/37]\tTime  4.226 ( 2.597)\tData  4.097 ( 2.468)\tLoss 1.8897e+00 (1.8396e+00)\tAcc@1  18.75 ( 17.76)\tAcc@5  80.47 ( 85.80)\n",
            "Train * Acc@1 17.756 Acc@5 85.795\n",
            "Train * Acc@1 17.904 Acc@5 85.286\n",
            "Train * Acc@1 17.548 Acc@5 84.856\n",
            "Train * Acc@1 17.243 Acc@5 84.654\n",
            "Train * Acc@1 17.552 Acc@5 84.948\n",
            "Train * Acc@1 17.725 Acc@5 84.961\n",
            "Train * Acc@1 17.509 Acc@5 85.202\n",
            "Train * Acc@1 17.057 Acc@5 84.983\n",
            "Train * Acc@1 16.941 Acc@5 84.868\n",
            "Train * Acc@1 17.109 Acc@5 84.609\n",
            "Epoch: [6][20/37]\tTime  7.458 ( 4.213)\tData  7.329 ( 4.084)\tLoss 1.8896e+00 (1.8468e+00)\tAcc@1  14.84 ( 17.00)\tAcc@5  78.12 ( 84.30)\n",
            "Train * Acc@1 17.001 Acc@5 84.301\n",
            "Train * Acc@1 16.832 Acc@5 83.700\n",
            "Train * Acc@1 16.882 Acc@5 83.628\n",
            "Train * Acc@1 16.667 Acc@5 83.757\n",
            "Train * Acc@1 16.750 Acc@5 83.906\n",
            "Train * Acc@1 16.797 Acc@5 83.804\n",
            "Train * Acc@1 16.580 Acc@5 83.825\n",
            "Train * Acc@1 16.546 Acc@5 83.873\n",
            "Train * Acc@1 16.514 Acc@5 83.890\n",
            "Train * Acc@1 16.693 Acc@5 83.880\n",
            "Epoch: [6][30/37]\tTime 10.739 ( 5.834)\tData 10.610 ( 5.705)\tLoss 1.8797e+00 (1.8486e+00)\tAcc@1   6.25 ( 16.36)\tAcc@5  80.47 ( 83.77)\n",
            "Train * Acc@1 16.356 Acc@5 83.770\n",
            "Train * Acc@1 16.406 Acc@5 83.667\n",
            "Train * Acc@1 16.217 Acc@5 83.712\n",
            "Train * Acc@1 16.245 Acc@5 83.778\n",
            "Train * Acc@1 16.384 Acc@5 83.482\n",
            "Train * Acc@1 16.341 Acc@5 83.594\n",
            "Train * Acc@1 16.280 Acc@5 83.509\n",
            "Test: [0/4]\tTime  0.868 ( 0.868)\tLoss 2.2777e+00 (2.2777e+00)\tAcc@1  18.75 ( 18.75)\tAcc@5  85.16 ( 85.16)\n",
            "Val * Acc@1 18.359 Acc@5 81.836\n",
            "Epoch: [7][ 0/37]\tTime  0.957 ( 0.957)\tData  0.814 ( 0.814)\tLoss 1.8669e+00 (1.8669e+00)\tAcc@1  16.41 ( 16.41)\tAcc@5  83.59 ( 83.59)\n",
            "Train * Acc@1 16.406 Acc@5 83.594\n",
            "Train * Acc@1 17.188 Acc@5 85.156\n",
            "Train * Acc@1 20.573 Acc@5 85.938\n",
            "Train * Acc@1 17.578 Acc@5 85.156\n",
            "Train * Acc@1 17.188 Acc@5 84.844\n",
            "Train * Acc@1 15.495 Acc@5 84.896\n",
            "Train * Acc@1 16.183 Acc@5 84.710\n",
            "Train * Acc@1 17.090 Acc@5 84.863\n",
            "Train * Acc@1 17.188 Acc@5 84.896\n",
            "Train * Acc@1 17.031 Acc@5 84.297\n",
            "Epoch: [7][10/37]\tTime  4.191 ( 2.566)\tData  4.063 ( 2.436)\tLoss 1.8340e+00 (1.8389e+00)\tAcc@1  17.97 ( 17.12)\tAcc@5  82.03 ( 84.09)\n",
            "Train * Acc@1 17.116 Acc@5 84.091\n",
            "Train * Acc@1 17.122 Acc@5 84.115\n",
            "Train * Acc@1 16.827 Acc@5 84.435\n",
            "Train * Acc@1 16.685 Acc@5 84.208\n",
            "Train * Acc@1 16.823 Acc@5 83.958\n",
            "Train * Acc@1 16.943 Acc@5 83.691\n",
            "Train * Acc@1 16.912 Acc@5 83.915\n",
            "Train * Acc@1 16.970 Acc@5 84.158\n",
            "Train * Acc@1 17.023 Acc@5 84.293\n",
            "Train * Acc@1 17.031 Acc@5 83.945\n",
            "Epoch: [7][20/37]\tTime  7.386 ( 4.173)\tData  7.257 ( 4.044)\tLoss 1.8548e+00 (1.8385e+00)\tAcc@1  17.19 ( 17.04)\tAcc@5  80.47 ( 83.78)\n",
            "Train * Acc@1 17.039 Acc@5 83.780\n",
            "Train * Acc@1 17.152 Acc@5 83.665\n",
            "Train * Acc@1 17.188 Acc@5 83.798\n",
            "Train * Acc@1 17.122 Acc@5 83.887\n",
            "Train * Acc@1 17.125 Acc@5 83.688\n",
            "Train * Acc@1 17.127 Acc@5 83.834\n",
            "Train * Acc@1 17.101 Acc@5 84.028\n",
            "Train * Acc@1 17.243 Acc@5 83.873\n",
            "Train * Acc@1 17.134 Acc@5 83.809\n",
            "Train * Acc@1 17.083 Acc@5 83.802\n",
            "Epoch: [7][30/37]\tTime 10.578 ( 5.772)\tData 10.450 ( 5.643)\tLoss 1.8264e+00 (1.8367e+00)\tAcc@1  16.41 ( 17.06)\tAcc@5  85.94 ( 83.87)\n",
            "Train * Acc@1 17.061 Acc@5 83.871\n",
            "Train * Acc@1 17.114 Acc@5 83.789\n",
            "Train * Acc@1 17.164 Acc@5 83.736\n",
            "Train * Acc@1 17.210 Acc@5 83.755\n",
            "Train * Acc@1 17.254 Acc@5 83.772\n",
            "Train * Acc@1 17.231 Acc@5 83.681\n",
            "Train * Acc@1 17.272 Acc@5 83.742\n",
            "Test: [0/4]\tTime  0.870 ( 0.870)\tLoss 2.2434e+00 (2.2434e+00)\tAcc@1  21.09 ( 21.09)\tAcc@5  82.81 ( 82.81)\n",
            "Val * Acc@1 19.141 Acc@5 80.469\n",
            "Epoch: [8][ 0/37]\tTime  2.635 ( 2.635)\tData  2.497 ( 2.497)\tLoss 1.8543e+00 (1.8543e+00)\tAcc@1  14.84 ( 14.84)\tAcc@5  80.47 ( 80.47)\n",
            "Train * Acc@1 14.844 Acc@5 80.469\n",
            "Train * Acc@1 13.281 Acc@5 78.125\n",
            "Train * Acc@1 14.583 Acc@5 81.250\n",
            "Train * Acc@1 13.867 Acc@5 81.250\n",
            "Train * Acc@1 15.781 Acc@5 81.875\n",
            "Train * Acc@1 15.365 Acc@5 82.292\n",
            "Train * Acc@1 15.625 Acc@5 82.589\n",
            "Train * Acc@1 15.625 Acc@5 83.008\n",
            "Train * Acc@1 15.538 Acc@5 82.726\n",
            "Train * Acc@1 15.547 Acc@5 82.891\n",
            "Epoch: [8][10/37]\tTime  5.858 ( 4.239)\tData  5.730 ( 4.110)\tLoss 1.8395e+00 (1.8397e+00)\tAcc@1  19.53 ( 15.91)\tAcc@5  80.47 ( 82.67)\n",
            "Train * Acc@1 15.909 Acc@5 82.670\n",
            "Train * Acc@1 16.471 Acc@5 82.878\n",
            "Train * Acc@1 16.887 Acc@5 82.812\n",
            "Train * Acc@1 16.685 Acc@5 82.701\n",
            "Train * Acc@1 16.771 Acc@5 82.917\n",
            "Train * Acc@1 16.992 Acc@5 82.666\n",
            "Train * Acc@1 16.820 Acc@5 82.583\n",
            "Train * Acc@1 16.840 Acc@5 82.726\n",
            "Train * Acc@1 16.776 Acc@5 82.484\n",
            "Train * Acc@1 16.680 Acc@5 82.656\n",
            "Epoch: [8][20/37]\tTime  9.106 ( 5.856)\tData  8.977 ( 5.727)\tLoss 1.8354e+00 (1.8359e+00)\tAcc@1  12.50 ( 16.48)\tAcc@5  84.38 ( 82.74)\n",
            "Train * Acc@1 16.481 Acc@5 82.738\n",
            "Train * Acc@1 16.761 Acc@5 82.706\n",
            "Train * Acc@1 16.984 Acc@5 82.812\n",
            "Train * Acc@1 16.960 Acc@5 82.845\n",
            "Train * Acc@1 17.156 Acc@5 83.031\n",
            "Train * Acc@1 17.188 Acc@5 83.083\n",
            "Train * Acc@1 17.043 Acc@5 83.160\n",
            "Train * Acc@1 16.881 Acc@5 83.231\n",
            "Train * Acc@1 17.080 Acc@5 83.378\n",
            "Train * Acc@1 17.109 Acc@5 83.464\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-031f26912a4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-031f26912a4b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0mbest_acc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mtrain_losses_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_top1_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_top5_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0mval_losses_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_top1_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_top5_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-031f26912a4b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, scheduler, epoch, args)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-031f26912a4b>\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_fmtstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mentries\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmeter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-031f26912a4b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_fmtstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mentries\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmeter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-031f26912a4b>\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mfmtstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{name} {val'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'} ({avg'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'})'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfmtstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_meta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Create torch dataset from images\n",
        "class ShapesDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, metadata, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.metadata = pd.read_csv(os.path.join(data_dir, metadata))\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.metadata)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if torch.is_tensor(index):\n",
        "            index = index.tolist()\n",
        "        \n",
        "        # Read images and targets\n",
        "        img_path = os.path.join(self.data_dir, self.metadata.iloc[index, 0])\n",
        "        image = Image.open(img_path)\n",
        "        label = self.metadata.iloc[index, 1]\n",
        "        \n",
        "        # # Convert image to channels first\n",
        "        # image = np.transpose(image, (2, 0, 1))\n",
        "\n",
        "        # Transform if requested\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "\n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def display(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print('\\t'.join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
        "\n",
        "\n",
        "def save_checkpoint(state, filename):\n",
        "    torch.save(state, filename)\n",
        "\n",
        "def cosine_annealing(step, total_steps, lr_max, lr_min): \n",
        "    return lr_min + (lr_max - lr_min) * 0.5 * (1 + np.cos(step / total_steps * np.pi))\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"\n",
        "    Computes the accuracy over the top k predictions for the specified values of k\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "\n",
        "        # print(\"RES array\", res)\n",
        "        return res\n",
        "\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, scheduler, epoch, args):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    data_time = AverageMeter('Data', ':6.3f')\n",
        "    losses = AverageMeter('Loss', ':.4e')\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    progress = ProgressMeter(\n",
        "        len(train_loader),\n",
        "        [batch_time, data_time, losses, top1, top5],\n",
        "        prefix=\"Epoch: [{}]\".format(epoch)\n",
        "    )\n",
        "\n",
        "    model.train()\n",
        "    start = time.time()\n",
        "\n",
        "    for i, (images, target) in enumerate(train_loader):\n",
        "        data_time.update(time.time() - start)\n",
        "\n",
        "        x = images.cuda().float()\n",
        "        y = target.cuda()\n",
        "\n",
        "        # print(f'**********IMAGE: {x[0]}')\n",
        "        # print(f'**********TARGET: {y}')\n",
        "        # print(f'**********TARGET TYPE: {type(y)}')\n",
        "\n",
        "        logits = model(x)\n",
        "        # print(f'**********LOGITS: {logits}')\n",
        "        loss = criterion(logits, y)\n",
        "        output, target = logits, y \n",
        "\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        losses.update(loss.item(), images.size(0))\n",
        "        top1.update(acc1[0], images.size(0))\n",
        "        top5.update(acc5[0], images.size(0))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        batch_time.update(time.time() - start)\n",
        "\n",
        "        if i % args.print_freq == 0:\n",
        "            progress.display(i)\n",
        "\n",
        "        print('Train * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
        "    \n",
        "    return losses.avg, top1.avg, top5.avg\n",
        "\n",
        "\n",
        "def val(test_loader, model, criterion, args):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    losses = AverageMeter('Loss', ':.4e')\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    progress = ProgressMeter(\n",
        "        len(test_loader),\n",
        "        [batch_time, losses, top1, top5],\n",
        "        prefix='Test: '\n",
        "    )\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        start = time.time()\n",
        "        for i, (images, target) in enumerate(test_loader):\n",
        "            images = images.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "            \n",
        "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "            losses.update(loss.item(), images.size(0))\n",
        "            top1.update(acc1[0], images.size(0))\n",
        "            top5.update(acc5[0], images.size(0))\n",
        "\n",
        "            batch_time.update(time.time() - start)\n",
        "\n",
        "            if i % args.print_freq == 0:\n",
        "                progress.display(i)\n",
        "\n",
        "        print('Val * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
        "\n",
        "    return losses.avg, top1.avg, top5.avg\n",
        "\n",
        "\n",
        "def main():\n",
        "    # parser = argparse.ArgumentParser(\n",
        "    #     description=\"Trains classifier on shapes dataset\", \n",
        "    #     formatter_class=argparse.ArgumentDefaultsHelpFormatter\n",
        "    # )\n",
        "    # parser.add_argument(\"--data\", \"-d\", type=str, default=\"./data/shapes\", choices=[\"./data/shapes\"])\n",
        "    # parser.add_argument(\"--model\", \"-m\", type=str, default=\"vgg16\")\n",
        "    # parser.add_argument(\"--num-workers\", type=int, default=2)\n",
        "    # parser.add_argument(\"--batch-size\", \"-b\", type=int, default=128)\n",
        "    # parser.add_argument(\"--pretrained\", \"-p\", action=\"store_true\")\n",
        "    # parser.add_argument(\"--print-freq\", \"-f\", type=int, default=10)\n",
        "    # # parser.add_argument(\"--gpu\", \"-g\", action=\"store_true\")\n",
        "    # parser.add_argument(\"--epochs\", default=10, type=int)\n",
        "    # parser.add_argument(\"--save-dir\", type=str, default=\"./checkpoints\")\n",
        "    # # Hyperparams adapted from http://cs231n.stanford.edu/reports/2017/pdfs/420.pdf\n",
        "    # parser.add_argument(\"--learning-rate\", \"-lr\", type=float, default=0.001, help=\"Initial learning rate.\")\n",
        "    # parser.add_argument(\"--momentum\", type=float, default=0.9)\n",
        "    # parser.add_argument(\"--decay\", \"-wd\", type=float, default=0.01)\n",
        "    # args = parser.parse_args()\n",
        "\n",
        "    # Make args as a class for running in colab\n",
        "    class Args:\n",
        "        def __init__(self, data='./images/shapes', model='vgg16', num_workers=2, batch_size=128, pretrained=False, print_freq=10, epochs=10, save_dir='./checkpoints', learning_rate=0.001, momentum=0.9, decay=0.01):\n",
        "            self.data = data\n",
        "            self.model = model\n",
        "            self.num_workers = num_workers\n",
        "            self.batch_size = batch_size\n",
        "            self.pretrained = pretrained\n",
        "            self.print_freq = print_freq\n",
        "            self.epochs = epochs\n",
        "            self.save_dir = save_dir\n",
        "            self.learning_rate = learning_rate\n",
        "            self.momentum = momentum\n",
        "            self.decay = decay\n",
        "\n",
        "    args = Args()\n",
        "\n",
        "\n",
        "    if args.data == \"./images/shapes\":\n",
        "        tub_train_transforms = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224),\n",
        "            transforms.RandomRotation(25),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            # TODO: properly calculate image statistics\n",
        "            transforms.Normalize([0.5] * 3, [0.5] * 3) \n",
        "        ])\n",
        "        tub_test_transforms = transforms.Compose([\n",
        "            transforms.Resize(255), \n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            # TODO: properly calculate image statistics\n",
        "            transforms.Normalize([0.5] * 3, [0.5] * 3)\n",
        "        ])\n",
        "\n",
        "        # Initialize train, val, test sets\n",
        "        train_data = ShapesDataset(metadata='metadata_whole.csv', data_dir = args.data, transform = tub_train_transforms)\n",
        "        val_data = ShapesDataset(metadata='metadata_whole.csv', data_dir = args.data, transform = tub_test_transforms)\n",
        "        test_data = ShapesDataset(metadata='metadata_whole.csv', data_dir = args.data, transform = tub_test_transforms)\n",
        "        \n",
        "        # Get train, val, test splits\n",
        "        train_size = 0.8\n",
        "        total_num_train = len(train_data.metadata)\n",
        "        indices = np.random.permutation(list(range(total_num_train)))\n",
        "        split = int(np.floor(train_size * total_num_train))\n",
        "        val_split = int(np.floor((train_size + (1 - train_size) / 2) * total_num_train))\n",
        "        train_idx, val_idx, test_idx = indices[:split], indices[split:val_split], indices[val_split:]\n",
        "        \n",
        "        # Subset train, val, test sets\n",
        "        train_data = torch.utils.data.Subset(train_data, indices=train_idx)\n",
        "        val_data = torch.utils.data.Subset(val_data, indices=val_idx)\n",
        "        test_data = torch.utils.data.Subset(test_data, indices=test_idx)\n",
        "\n",
        "    else:\n",
        "        raise Exception(f\"{args.data} is not a supported dataset\")\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_data, \n",
        "        batch_size=args.batch_size,\n",
        "        num_workers=args.num_workers, \n",
        "        shuffle=True,\n",
        "        # Unclear if we need drop_last, e.g. AugMix doesn't have this\n",
        "        drop_last=True)\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_data, \n",
        "        batch_size=args.batch_size,\n",
        "        num_workers=args.num_workers, \n",
        "        shuffle=True,\n",
        "        # Unclear if we need drop_last, e.g. AugMix doesn't have this\n",
        "        drop_last=True)\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_data, \n",
        "        batch_size=args.batch_size,\n",
        "        num_workers=args.num_workers, \n",
        "        shuffle=True,\n",
        "        # Unclear if we need drop_last, e.g. AugMix doesn't have this\n",
        "        drop_last=True)\n",
        "\n",
        "    if args.model == \"vgg16\":\n",
        "        model = models.vgg16(pretrained=args.pretrained)\n",
        "        features = []\n",
        "        for feat in list(model.features):\n",
        "            features.append(feat)\n",
        "            if isinstance(feat, nn.Conv2d):\n",
        "                features.append(nn.Dropout(p=0.5, inplace=True))\n",
        "\n",
        "        model.features = nn.Sequential(*features)\n",
        "        print(model)\n",
        "    else:\n",
        "        raise Exception(f\"{args.model} is not a supported model\")\n",
        "\n",
        "\n",
        "    model = torch.nn.DataParallel(model).cuda()\n",
        "    criterion = nn.CrossEntropyLoss().cuda()\n",
        "    optimizer = torch.optim.SGD(\n",
        "        model.parameters(),\n",
        "        args.learning_rate,\n",
        "        momentum=args.momentum,\n",
        "        weight_decay=args.decay,\n",
        "        nesterov=True\n",
        "    )\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
        "        optimizer,\n",
        "        lr_lambda=lambda step: cosine_annealing( \n",
        "            step,\n",
        "            args.epochs * len(train_loader),\n",
        "            1,  \n",
        "            1e-6 / args.learning_rate\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # MAIN TRAINING LOOP\n",
        "    best_acc1 = 0\n",
        "    for epoch in range(args.epochs):\n",
        "        train_losses_avg, train_top1_avg, train_top5_avg = train(train_loader, model, criterion, optimizer, scheduler, epoch, args)\n",
        "        val_losses_avg, val_top1_avg, val_top5_avg = val(val_loader, model, criterion, args)\n",
        "\n",
        "        if not os.path.exists(os.path.join(args.save_dir, \"training_log.csv\")):\n",
        "          os.makedirs(args.save_dir)\n",
        "          os.system('touch training_log.csv')\n",
        "          \n",
        "        with open(os.path.join(args.save_dir, \"training_log.csv\"), \"a+\") as f:\n",
        "            f.write('%03d,%0.5f,%0.5f,%0.5f,%0.5f,%0.5f,%0.5f\\n' % (\n",
        "                (epoch + 1),\n",
        "                train_losses_avg, train_top1_avg, train_top5_avg,\n",
        "                val_losses_avg, val_top1_avg, val_top5_avg\n",
        "            )\n",
        "        )\n",
        "\n",
        "        best_acc1 = max(val_top5_avg, best_acc1)\n",
        "        save_file = os.path.join(args.save_dir, \"final_model.pth\")\n",
        "        save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'arch': args.model,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'best_acc1': best_acc1,\n",
        "            'optimizer' : optimizer.state_dict(),\n",
        "        }, filename=save_file)\n",
        "\n",
        "    best_cp = torch.load(save_file)\n",
        "    model.load_state_dict(best_cp[\"state_dict\"])\n",
        "    test_losses_avgs, test_top1_avg, test_top5_avg = val(test_loader, model, criterion, args)\n",
        "    print(f'Test * Acc@1 {test_top1_avg} Acc@5 {test_top5_avg}')\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv('training_log.csv', header=None)\n",
        "df.columns = ['epoch', 'train_loss', 'train_acc1', 'train_acc5', 'val_loss', 'val_acc1', 'val_acc5']\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(df['epoch'], df['train_loss'], label='train')\n",
        "plt.plot(df['epoch'], df['val_loss'], label='val')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(df['epoch'], df['train_acc1'], label='train')\n",
        "plt.plot(df['epoch'], df['val_acc1'], label='val')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.10.7 ('_NAP': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "79def0c0aeed0307f0b7b7c13e84f80aa4409d9b4e442ea2e585af93b299d2b2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
